# 🕰️ linux智能日志清理：用 Bash 脚本自动保留最近 3 个月日志，告别磁盘爆满！

在现代运维体系中，日志是系统的眼睛，但也是磁盘空间的“吞噬者”。每天成千上万的日志文件不断堆积，若不加以管理，轻则占用大量存储资源，重则导致服务崩溃。然而，盲目删除又可能丢失关键排查线索。**如何在“保留必要日志”与“释放磁盘空间”之间取得平衡？** 本文将带你深入剖析一个高效、安全、可扩展的日志自动清理脚本，并从原理到实践层层递进，让你不仅会用，更懂其所以然。

---

## 1. 脚本核心逻辑解析

### 1.1 基础需求与目标

我们的目标非常明确：**自动删除 `/var/logs` 目录下超过 3 个月历史的日志文件，仅保留最近 90 天内的日志用于问题回溯**。这看似简单，但背后涉及时间计算、文件属性读取、边界条件处理等多个技术点。

> 💡 **为什么是 3 个月？**  
> 这是业界常见实践：既满足 GDPR 等合规性审计周期（通常 90 天），又能覆盖大多数线上问题的复现窗口期。



## 2. 打造工业级日志清理脚本

### 2.1 设计原则

- ✅ **安全第一**：dry-run 模式、确认删除、路径校验  
- ✅ **精准时间判断**：使用 Unix 时间戳直接比较  
- ✅ **健壮性**：处理特殊文件名、跳过非普通文件  
- ✅ **可配置性**：保留天数、日志目录、日志后缀均可调  
- ✅ **可观测性**：详细日志输出 + 错误处理

### 2.2 完整脚本

```bash
#!/bin/bash

# ==================================================
# 智能日志清理脚本 v2.0
# 功能：自动删除指定目录下超过 N 天的日志文件
# 作者：DevOps Engineer
# ==================================================

set -euo pipefail  # 严格错误处理

# ----------------------------
# 1. 配置参数（可外部传入）
# ----------------------------
LOG_DIR="${1:-/var/logs}"          # 日志目录（默认 /var/logs）
RETAIN_DAYS="${2:-90}"             # 保留天数（默认 90 天）
DRY_RUN="${3:-false}"              # 是否仅预览（true/false）

# ----------------------------
# 2. 安全校验
# ----------------------------
if [[ ! -d "$LOG_DIR" ]]; then
  echo "❌ 错误：日志目录不存在 - $LOG_DIR" >&2
  exit 1
fi

# 防止误删根目录（常见陷阱！）
case "$LOG_DIR" in
  "/"|"/etc"|"/bin"|"/usr"|"/lib"*)
    echo "❌ 危险操作：禁止清理系统关键目录！" >&2
    exit 1
    ;;
esac

# ----------------------------
# 3. 计算时间阈值（Unix 时间戳）
# ----------------------------
CURRENT_TS=$(date +%s)
THRESHOLD_TS=$((CURRENT_TS - RETAIN_DAYS * 86400))  # 86400 = 24*60*60

echo "📅 当前时间: $(date -d "@$CURRENT_TS" '+%Y-%m-%d %H:%M:%S')"
echo "⏳ 保留阈值: $(date -d "@$THRESHOLD_TS" '+%Y-%m-%d %H:%M:%S') (最近 $RETAIN_DAYS 天)"
echo "📂 扫描目录: $LOG_DIR"
echo "🔍 模式: ${DRY_RUN:+[预览模式] }"

# ----------------------------
# 4. 遍历文件并处理
# ----------------------------
# 使用 find 避免空格问题，且只处理普通文件
while IFS= read -r -d '' file; do
  # 跳过非普通文件（目录、设备等）
  [[ -f "$file" ]] || continue

  # 获取文件修改时间（Unix 时间戳）
  MOD_TS=$(stat -c %Y "$file" 2>/dev/null || echo 0)

  # 跳过无法读取时间的文件
  if [[ $MOD_TS -eq 0 ]]; then
    echo "⚠️  警告：无法获取文件时间 - $file"
    continue
  fi

  # 判断是否过期
  if [[ $MOD_TS -lt $THRESHOLD_TS ]]; then
    if [[ "$DRY_RUN" == "true" ]]; then
      echo "🗑️  [预览] 将删除: $file (修改于 $(date -d "@$MOD_TS" '+%Y-%m-%d'))"
    else
      rm -f "$file"
      echo "✅ 已删除: $file (修改于 $(date -d "@$MOD_TS" '+%Y-%m-%d'))"
    fi
  else
    echo "📌 保留: $file (修改于 $(date -d "@$MOD_TS" '+%Y-%m-%d'))"
  fi

# 使用 null 分隔符安全处理含空格文件名
done < <(find "$LOG_DIR" -type f -print0)

echo "✨ 清理完成！"
```

### 2.3 关键改进详解

#### 2.3.1 使用 `find ... -print0` + `read -d ''`

```bash
while IFS= read -r -d '' file; do ... done < <(find "$LOG_DIR" -type f -print0)
```

- `-print0`：用 null 字符分隔文件名（而非换行）
- `read -d ''`：以 null 为分隔符读取
- **完美解决文件名含空格、换行、特殊符号的问题**

#### 2.3.2 直接比较 Unix 时间戳

```bash
THRESHOLD_TS=$((CURRENT_TS - RETAIN_DAYS * 86400))
if [[ $MOD_TS -lt $THRESHOLD_TS ]]; then ...
```

- 避免日期格式转换误差
- 跨年、闰年、时区问题一并解决
- 性能更高（整数比较 vs 字符串解析）

#### 2.3.3 三重安全防护

1. **路径白名单校验**：拒绝清理 `/`, `/etc` 等危险目录  
2. **Dry-run 模式**：`./clean_logs.sh /var/mylogs 30 true` 先预览再执行  
3. **严格错误处理**：`set -euo pipefail` 确保任何错误立即退出

---

## 3. 高级技巧与最佳实践

### 3.1 集成到生产环境

#### 3.1.1.1 配置定时任务（Cron）

```bash
# 每天凌晨 2 点执行（保留 90 天）
0 2 * * * /opt/scripts/clean_logs.sh /var/app_logs 90 false >> /var/log/clean_logs.log 2>&1
```

#### 3.1.1.2 日志轮转配合

建议先用 `logrotate` 按天分割日志，再用本脚本清理旧文件：

```conf
# /etc/logrotate.d/myapp
/var/app_logs/*.log {
  daily
  rotate 30
  compress
  missingok
  notifempty
}
```

> 🔄 **组合拳**：`logrotate` 负责单文件切割，本脚本负责历史版本清理。

### 3.2 扩展功能建议

#### 3.2.1.1 按文件名过滤

```bash
# 只清理 .log 或 .gz 文件
find "$LOG_DIR" -type f \( -name "*.log" -o -name "*.gz" \) -print0
```

#### 3.2.1.2 保留最新 N 个文件（防突发日志）

```bash
# 在删除前保留每个服务最新的 5 个日志
ls -t service_*.log | tail -n +6 | xargs rm -f
```

#### 3.2.1.3 发送清理报告

```bash
# 脚本末尾添加
echo "共删除 $deleted_count 个文件，释放 $(du -sh "$LOG_DIR" | cut -f1)" | mail -s "日志清理报告" admin@example.com
```

---

## 4. 总结与思考

### 4.1 核心收获

- **时间处理**：Unix 时间戳是跨平台时间比较的黄金标准  
- **安全意识**：任何涉及 `rm` 的脚本必须有 dry-run 和路径校验  
- **健壮性设计**：用 `find -print0` 处理文件名，用 `set -euo pipefail` 防御错误  
- **运维哲学**：自动化 ≠ 无人值守，可观测性与可回滚性同样重要

### 4.2 延伸思考

> 🤔 **如果日志量极大（TB 级），遍历效率如何优化？**  
> 答：可结合 `find -mtime +90 -delete` 直接删除，但牺牲了精细控制。对于超大规模场景，建议使用专用工具如 `tmpwatch` 或对象存储生命周期策略。

---

**最后提醒**：脚本是工具，思维是核心。真正的运维高手，不仅会写脚本，更懂得在“自动化”与“可控性”之间找到平衡点。现在，就用这个增强版脚本，给你的服务器来一次清爽的日志大扫除吧！🧹