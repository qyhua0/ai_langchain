# LLM模型配置文件
llm_configs:
  - name: "deepseek_chat"
    provider: "deepseek"
    model: "deepseek-chat"
    temperature: 0.3
    max_tokens: 4000
    base_url: "https://api.deepseek.com/v1"
    # api_key: "your_deepseek_api_key"  # 或使用环境变量 DEEPSEEK_API_KEY

  - name: "gpt4"
    provider: "openai"
    model: "gpt-4"
    temperature: 0.2
    max_tokens: 3000
    # api_key: "your_openai_api_key"  # 或使用环境变量 OPENAI_API_KEY

  - name: "gpt4_creative"
    provider: "openai"
    model: "gpt-4"
    temperature: 0.4
    max_tokens: 4000
    # api_key: "your_openai_api_key"

  - name: "qwen3:14b"
    provider: "ollama"
    model: "qwen3:14b"
    temperature: 0.3
    base_url: "http://localhost:11434"

  - name: "gpt4_reviewer"
    provider: "openai"
    model: "gpt-4"
    temperature: 0.1
    max_tokens: 2000
    # api_key: "your_openai_api_key"